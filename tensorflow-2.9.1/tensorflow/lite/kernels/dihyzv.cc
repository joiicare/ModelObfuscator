/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

#include "tensorflow/lite/kernels/internal/optimized/integer_ops/depthwise_conv.h"

#include <stddef.h>
#include <stdint.h>
#include <vector>

#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/common.h"
#include "tensorflow/lite/kernels/cpu_backend_context.h"
#include "tensorflow/lite/kernels/internal/compatibility.h"
#include "tensorflow/lite/kernels/internal/optimized/cpu_check.h"
#include "tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h"
#include "tensorflow/lite/kernels/internal/optimized/integer_ops/depthwise_conv_hybrid.h"
#include "tensorflow/lite/kernels/internal/optimized/neon_check.h"
#include "tensorflow/lite/kernels/internal/quantization_util.h"
#include "tensorflow/lite/kernels/internal/reference/depthwiseconv_float.h"
#include "tensorflow/lite/kernels/internal/reference/depthwiseconv_uint8.h"
#include "tensorflow/lite/kernels/internal/reference/integer_ops/depthwise_conv.h"
#include "tensorflow/lite/kernels/internal/tensor.h"
#include "tensorflow/lite/kernels/internal/tensor_ctypes.h"
#include "tensorflow/lite/kernels/internal/tensor_utils.h"
#include "tensorflow/lite/kernels/internal/types.h"
#include "tensorflow/lite/kernels/kernel_util.h"
#include "tensorflow/lite/kernels/padding.h"

namespace tflite {
namespace ops {
namespace custom {
namespace dihyzv {

constexpr int kInputTensor = 0;
constexpr int kFilterTensor = 1;
constexpr int kBiasTensor = 2;
constexpr int kOutputTensor = 0;

// This file has three implementation of DepthwiseConv.
enum KernelType {
  kReference,
  kGenericOptimized,  // Neon-free
  kNeonOptimized,
};

const int kTensorNotAllocated = -1;

int8_t filter_r   aw[6000]={-6, -1, 5, 4, 8, 37, -5, -3, -5, -7, -3, -9, -10, 0, 3, -9, 9, -6, 12, 1, 0, -1, -7, 15, -2, -8, 2, 0, -5, 2, -8, 19, -13, 0, -9, 6, -2, 5, 2, -10, -9, -2, -1, -6, 4, -9, -2, 6, 3, -8, 2, -4, -2, -25, -127, -5, -14, 6, 2, 9, -1, 1, 8, -9, 14, 1, -8, 0, 8, -3, -20, -7, 1, 4, 14, 5, -8, 3, 3, 1, 4, 0, -39, -2, -1, -10, -6, -2, 2, -8, 57, -5, 13, 7, -4, -1, 2, -4, -6, 7, -2, -18, 7, -1, -2, -5, 1, 8, -8, 7, 0, -4, 3, -9, -3, -1, -12, -2, 9, 3, -4, -1, 12, -3, -1, 7, -5, -3, 0, 1, 3, -42, -31, -118, -6, -2, 0, -9, -12, -4, -53, 7, -1, 8, 6, -4, 5, -1, -2, 2, 8, 2, 7, -2, -9, -6, -3, -1, -2, 22, 21, 6, 0, -11, 1, -8, 0, 5, 5, -51, 2, -2, 0, -14, -18, 11, 1, -13, 9, -7, -4, -21, 2, 3, -4, 7, -16, 3, 2, 5, -6, -13, 14, -2, 3, 5, -2, 27, 11, -33, 16, 7, 1, 5, -54, 1, 24, -9, -7, 6, -1, 5, -3, -2, 4, 5, 11, -15, -3, -4, 14, -8, 7, -5, 0, 0, 8, -9, 2, 0, -7, -10, 5, 2, -3, -15, 13, -6, -10, -1, -11, 6, 18, -5, 2, 17, 1, 0, 0, -8, 7, -3, -40, 6, 5, -16, 17, -7, 30, -34, 0, -6, -4, -22, -31, 6, -5, 6, 6, -4, -23, -1, -4, -5, -9, 15, 0, -2, 0, 14, -12, 1, -8, 2, 2, -8, -15, 15, 2, 1, 4, -11, -11, -15, -85, 4, -21, 5, -29, 20, 27, -3, -13, 43, 25, -17, -3, -21, 19, -6, -1, 15, -1, -10, 13, 6, 14, 5, 3, -9, -9, -6, 25, 33, -6, -17, 22, 10, 3, -2, 12, -12, 6, 17, -11, 7, 10, 5, -7, -3, -9, 2, 3, 2, 2, -11, -3, 24, -10, -7, -5, -4, -12, -3, 0, -11, 9, 4, -7, -5, 4, 11, 12, -2, -8, 2, -11, 2, 10, -1, -11, -30, 15, -75, -9, -5, 14, 4, -17, 35, -30, 18, -5, 12, -14, -1, -4, -25, 6, -6, 14, -3, 4, -7, 10, 3, 10, -4, 0, -53, 11, 3, 4, -15, -11, -8, 12, 3, 6, -23, -7, 2, 7, -4, -14, 4, 2, -9, 2, -15, -3, -20, 20, 8, 0, -5, -42, -3, -1, 2, -5, -10, -38, 0, 12, -4, -9, -5, 7, -37, 13, -8, 10, 2, -32, 1, 4, 14, -7, 11, -3, 16, 3, 5, 0, -11, -8, -13, -5, 19, 17, -1, -12, -9, -8, -3, 25, 9, -7, 3, -2, -11, 9, 0, -6, -18, -1, -7, 14, 5, 0, -15, 23, 7, -1, -16, 11, 11, 2, -22, -9, -12, -72, -1, -4, -8, 34, -31, -61, -83, 2, -11, 3, -23, -39, 20, -26, 2, -12, -30, -26, -60, 13, 6, -23, 14, -23, 3, -4, -15, -26, -8, 12, 19, -5, -20, -17, -24, -20, -14, 16, -54, -23, 18, -95, -8, -31, 6, 0, 1, -9, -29, -4, 48, 27, 17, -3, 9, 30, 30, -88, -16, 2, -12, 0, 13, -23, -2, -5, 1, -7, 25, -20, 21, 13, -35, -69, -15, 14, -1, -66, -1, 4, 33, -28, 6, 2, -9, -14, 48, -27, -9, 5, -29, 14, -52, -20, -20, -21, -5, 3, 1, -9, -3, 8, 22, -67, 9, -4, 19, -19, -20, -11, 9, -2, -32, -17, -7, 14, 5, -9, 20, -44, -82, -1, 7, -18, 0, -18, -21, -124, 32, -6, 26, 5, 9, 13, -78, 1, -6, 37, 19, -2, 8, -10, 9, 34, -4, -31, 21, -5, 3, 5, -22, -2, -34, 21, 10, 13, -48, 3, -27, 2, 2, -35, 4, 10, -52, -36, 79, -13, -36, 16, -1, 6, 7, -127, 18, 11, 6, 88, 0, -72, -5, 4, 1, -29, -25, -15, -127, 30, 25, -1, -2, -79, -12, -2, -2, -3, 18, -1, 36, -1, -30, 4, -24, -29, -38, 6, 4, -4, 10, -2, 24, 0, 0, 6, -36, 18, -36, -3, -30, 2, 10, -10, 30, -31, -19, -37, -21, 16, 6, -31, -5, -1, -12, 8, 3, 2, -6, -5, -8, -39, 4, 1, -12, 16, -12, 24, -17, 1, -3, 4, -17, -16, 6, -2, -17, 4, -2, -19, -2, 9, -10, -11, -10, -1, -1, 0, 9, 17, -6, -7, 0, 2, -7, -7, 20, 4, 5, 0, 23, -6, -5, -95, -7, -19, 1, 7, -2, -15, -10, -15, -3, 26, 11, 4, -6, 20, -6, -11, 5, 12, -9, 8, 4, 13, -3, -3, -7, -8, -1, -12, 27, -8, -16, 2, 7, 1, 1, -18, 4, 8, 16, -11, 7, -44, -2, -7, -5, -11, -12, 5, 0, 1, -13, -3, -9, 9, -5, -5, 15, -4, -1, 0, -8, 6, 6, -6, -8, -6, -6, 3, 15, -7, 20, 26, 3, 10, 5, 28, -9, 12, -89, -12, -2, 1, -3, -16, -21, -23, 17, -5, 1, -3, 39, 21, -50, 4, -2, 13, 10, -3, -4, 2, -7, -52, -2, -2, 17, 2, 1, -8, -20, -12, -9, 9, 8, 3, -34, 10, 2, 6, 7, -15, 1, 1, -7, 0, -14, 1, -25, -4, 0, -3, -7, -46, -24, -1, 5, -2, -3, -21, -1, 13, -9, -10, -8, -2, -43, -25, 27, 6, -1, -50, -1, -2, 2, -9, 11, 18, 21, 1, 1, 1, -12, -8, -18, -6, 11, 12, -3, 7, -1, -6, -1, -14, -31, -10, 1, 6, -10, -4, 1, -10, 8, 1, -3, -27, 4, 3, 2, -71, 8, -7, -3, 4, 4, -5, -5, 1, -11, -5, -1, 6, -11, 4, -5, 6, -6, 0, -1, 6, -7, -13, -3, 0, 5, -3, 1, -11, 18, 3, 1, -9, 7, -2, 7, 2, -15, 23, 0, -2, -1, 3, -7, 11, 4, 2, -7, 0, 4, -4, -21, -118, -4, -17, 7, 3, 4, 3, -3, 1, -6, 14, 13, 4, 4, 10, -6, -7, -10, 5, 4, 5, 4, -7, -2, -1, 2, 2, -3, 66, -8, -7, -7, -18, -1, 2, 6, -36, -2, 9, 6, -8, 1, 3, 2, -5, 9, -1, -3, 4, -2, -1, -5, 1, -4, -4, 6, 1, -5, 2, 7, -2, -1, -13, -3, 13, 0, -8, 3, 7, 0, -3, -26, -2, -2, 4, -3, -6, -3, -5, -102, -7, -1, 5, 0, -14, 3, -50, 6, 5, 21, 8, 0, 6, -5, 0, -1, 7, -2, -6, -3, -5, 0, 10, -1, -1, 2, 15, 0, -4, -6, -1, -11, 2, 12, 5, -55, -5, -2, 4, -7, -18, 6, 1, -19, 7, -9, -25, -22, 7, 1, -11, 9, 1, -5, -1, 2, -4, -14, -35, -2, -1, -1, 3, 25, -1, -20, 2, -24, 3, -7, -22, 0, 4, 2, -5, 3, -6, 5, -1, 0, 2, 4, 14, -18, -2, -2, 27, -3, 5, 12, -3, 0, -16, -11, 1, 0, 5, -10, 4, 2, 1, 1, 11, -12, -51, -2, 6, 6, -75, 3, 23, -73, -5, 8, 4, -9, 26, -4, -12, 7, 4, -11, 2, 0, -12, 10, -3, 8, -18, -6, -13, -10, -2, -11, -5, -1, -14, -12, -17, 8, -9, 14, 1, 9, 0, 2, 3, -1, -4, -5, 3, -11, 3, 16, 0, -5, 9, 16, -8, -23, -49, 8, -22, 8, 6, 0, -3, -9, -12, 39, 22, 40, -21, 9, 3, -9, -9, -5, 15, -6, 5, 7, 1, 21, -7, 10, 7, 0, -40, 31, 6, -2, -5, -3, 18, -20, 91, 17, 7, 2, -6, 2, -24, -4, 1, 8, -2, -2, 2, 3, -2, -7, -3, -3, -10, -3, 7, 12, -7, -21, 7, 9, -2, 3, -1, 9, 0, 7, 8, 6, 11, 2, 11, 1, -5, 0, 13, 37, 20, -105, -3, 4, 1, -3, -16, -49, -16, 5, 8, -4, -14, -6, 20, -4, -6, -1, 4, -8, 19, -8, 0, -6, 0, 1, 0, 23, 29, -6, -1, -15, -8, -23, -3, 7, 4, -47, 14, -14, 4, 11, -8, 8, 0, -9, -15, 10, -4, -18, 0, 16, -4, 0, -41, 4, 11, -1, 26, 3, -15, 3, 17, -7, -2, -6, 3, -34, -9, -10, -1, 23, -23, 3, 36, 16, -1, 1, -1, 1, 1, 3, 2, 2, 2, -18, -8, -18, 15, 15, -10, -16, -9, -4, -4, -28, 6, -1, -19, -13, -7, 0, 2, -10, 19, -3, -22, 13, -12, 2, -25, 8, 49, -24, -20, -66, -13, -41, 70, 5, -48, 13, 6, -38, 41, -33, 14, -47, 3, 0, -35, -2, -31, -6, 8, -40, 11, 3, -7, 59, 26, 20, 2, -16, 5, 9, 4, -7, -72, -8, -9, 13, 1, -2, -5, -12, 4, -5, -15, -127, -21, -51, -56, 54, -33, 17, 30, 0, 6, -3, -17, 127, -9, 26, -36, 19, 40, -3, -5, 12, -12, -1, 73, 10, -24, 36, 10, 21, 16, -13, -4, -39, 16, -42, -69, -10, 12, -38, 43, 6, 9, 42, -39, -12, -21, -1, -40, 7, -38, -6, 41, 0, 0, 14, -16, -9, -16, 1, 7, -2, 9, -48, 5, -38, 16, 11, -65, 8, -6, 51, 6, 33, -34, -33, -30, 1, 11, 16, -31, 6, -81, -79, -13, 5, -13, -42, 3, 75, 32, 47, -2, 30, -21, -16, 53, 112, 26, 6, 42, 11, 44, 0, -25, 66, 14, -16, 5, -33, -11, -18, 0, -10, 10, 13, 27, -2, 4, 41, 24, -27, -5, -11, -2, 6, 0, -14, 26, -39, -51, 27, -24, 28, -3, 14, -7, -12, 38, -1, 2, -5, -54, -5, 0, 4, 47, 8, -27, -32, -15, -86, 8, 42, 58, 0, -1, 81, -21, 37, -24, 9, 11, 20, -5, -12, -4, -20, 2, 15, -2, 1, 21, 22, -2, -4, 19, -18, 7, 2, -44, -40, 42, 3, -21, -4, 7, -25, 29, -6, -127, -9, -6, 49, -3, 71, -48, 19, -28, -31, -27, 45, 21, -67, 17, -44, 122, -121, -113, -24, 68, -66, 4, -121, -13, 93, 72, 12, 7, -27, -5, -22, -41, -56, 5, 86, -32, -65, 14, 41, -44, 5, 36, 51, -18, -27, -35, -84, -32, 56, 16, -86, -21, 118, -54, -22, -10, 2, 18, 127, 35, -17, 48, 56, -127, 20, 16, -27, 125, 115, -123, -3, -31, -11, 61, -10, -2, -1, 86, -67, -62, -57, 54, -118, -39, -127, -86, 15, -60, 9, 53, 2, 14, 119, -49, -5, 25, 53, -107, 70, -127, 63, 83, -38, 44, 20, -11, -127, 39, 5, -38, 19, 127, 4, 17, -14, -40, -14, -102, -29, -19, -19, 19, 127, -127, -122, 48, 16, 55, 40, 25, 4, -125, -44, -39, -15, -127, 0, 49, 49, 57, 125, 0, 110, 45, -47, 49, -1, 70, -1, 124, 40, -4, -3, -61, 82, -53, 6, -22, -86, -119, 29, 17, 29, 69, 39, 107, 23, 13, 84, 2, -49, 0, 41, 6, 41, 16, -81, 3, 55, 60, 79, 39, -13, 46, 44, -57, -32, 127, 27, -41, -36, -11, -1, 1, 61, 29, -83, -127, -89, 19, 19, 66, -9, 12, -22, -119, -32, -50, 113, -24, 101, 6, -40, 7, -11, -37, -29, 2, -21, -3, 0, 15, 113, 9, 15, 18, -25, 20, -4, 0, -11, -21, 23, -75, 112, -123, -127, -108, -43, -71, 3, -38, 11, -45, 32, -16, 40, -11, -41, -47, 5, -46, 12, 2, -38, 42, -35, 13, 107, 8, 4, 38, 16, -27, 7, 11, 29, 7, 3, 1, 60, -74, 21, 4, -10, 4, 9, -1, -2, 77, 9, -12, 1, -7, -6, -10, -80, 10, -11, -17, -61, -19, -38, -48, -59, -25, 16, -18, 28, -29, -9, -3, -82, -12, -5, 44, -5, 39, -16, -46, 16, 41, -2, -31, 9, -21, -32, 18, 18, 14, -5, 29, -38, 3, -39, -13, -10, 12, 45, -1, 12, 5, 40, -34, 6, 39, 10, -35, 11, -43, -42, 52, 7, 2, 8, -18, 17, -4, 5, 20, -12, 30, 45, 6, -41, 11, 11, -61, 8, 18, -54, -3, -3, -15, -80, 65, 3, 18, 19, 10, -42, -16, -85, -15, 6, -7, 36, 6, -27, 36, 45, 12, 30, -1, 113, -15, -40, 25, 0, 37, 22, -44, 3, -22, -87, -36, -18, 3, 33, -19, -9, 0, -1, 15, 19, 36, -22, 9, 59, -26, -22, -5, -7, 3, 17, 0, -18, 1, -28, -5, 55, 52, -40, 12, 13, -16, 38, -14, 2, 6, -1, 46, -4, -1, -1, -17, -15, -14, -45, 41, 127, 26, -43, -47, 1, 5, -29, -22, 36, 77, 6, 13, 17, 2, -20, -8, -16, 4, 8, 35, 4, -25, -14, -13, -3, -34, -13, 8, 2, 44, -36, -15, 4, -21, 4, 10, -26, -23, -10, -1, 4, 62, -4, -23, 31, 1, -13, 7, -9, -25, -10, -30, 4, 2, -13, 1, -5, -3, -6, -7, 2, 18, 28, -3, -10, -5, 0, -5, 1, -19, -5, -30, 8, -12, 18, -2, 13, 5, 4, 32, -10, -6, -8, 3, -10, 3, 32, 2, -8, 10, -25, -7, -26, -63, -10, -23, 5, -15, 8, 8, -8, -9, -38, 29, -9, 25, 4, 1, -13, -28, 9, -10, -9, 3, 5, 2, -17, -2, 8, 10, -6, 17, 28, 9, 0, -5, -1, 18, 25, -76, 5, 5, 3, -13, 8, 23, -5, 1, 7, -3, -6, 4, 1, -6, -7, -3, -14, -14, -4, 5, -5, 6, 20, 5, 11, 4, 3, -11, 9, 0, -9, 11, -7, 5, 3, -40, -7, -3, 0, -1, -51, 11, -110, -1, 1, -5, 12, -18, 7, -14, 3, -11, 2, 0, 52, -6, -1, -4, 2, 2, -2, -20, -7, -4, -4, 25, -5, -2, -4, 24, -7, 17, -17, -4, -16, -4, 2, 4, -56, -9, -10, 3, -7, -10, 14, 1, -10, -5, -1, -3, -12, 20, -17, -2, 0, -17, 18, -20, 0, 25, 1, 16, 3, 17, 2, -1, -20, 6, -2, 60, 12, -2, -19, -40, 6, 2, -2, 3, 4, 7, -4, -2, 4, 1, 1, 2, -26, -9, -8, 10, 10, -10, -16, -12, -3, 19, 1, 5, -4, 17, -14, 13, 0, 4, -6, 20, 0, -34, 13, 1, 2, 48, -10, 45, -8, 15, 51, 11, -24, -18, -4, -27, -11, -7, -14, -6, -6, 1, -5, 4, 20, -55, -82, -23, 10, 7, 5, 17, -26, -40, -44, 31, 10, -23, 9, -16, 22, -5, 10, -20, -12, 14, -4, -10, -12, -29, -24, -21, -18, 8, -18, -18, 46, -84, -8, -36, 4, -22, -16, 1, -28, -4, -22, 24, -8, -49, -34, -2, -4, -45, 5, 18, -30, -14, 12, 25, 37, 6, 12, 9, 14, 59, 25, 20, -3, 5, 10, 50, -44, 44, -54, 0, -1, -23, 8, -30, -1, -14, 14, -5, -5, -38, -17, 16, -51, -18, 7, -26, -12, 7, 34, 0, -46, 3, -4, -76, 8, -18, -1, -1, -17, 0, -5, -20, -35, 1, -1, 10, 11, -2, 36, -30, -125, -6, 4, -18, -25, -14, 6, -127, -4, -4, 16, 1, -3, 2, -7, 0, -1, -1, 13, 42, 11, -28, -4, -10, -10, -32, -9, -10, 6, -27, -27, -8, -43, 9, -6, 13, -49, 29, 0, -2, 37, -35, -4, 10, -66, -11, 7, -14, -31, -3, 49, 19, -1, -105, -41, 23, -19, 27, 2, -39, -8, 27, -8, -30, -74, -34, -94, 1, 2, 6, 45, -32, -4, 40, 12, 5, -3, 14, -36, 11, -30, 8, -7, -22, -44, 16, 4, 3, -21, 6, 21, -13, 12, -32, -2, -11, -36, -58, -23, 17, 11, -24, 33, 1, -10, 11, -17, 33, -72, 109, 9, 124, -77, -64, -127, 33, -22, -3, -24, 8, -36, 20, -38, -11, -8, 37, 97, -22, 112, -127, -90, -30, 31, 11, 45, 10, 10, 73, -27, 106, 55, 0, 87, -11, 56, 14, 3, -115, 21, 49, -23, -19, -28, -35, -108, -35, -87, -31, -112, -24, -52, -54, -7, -24, 3, 41, -113, 10, -4, 38, -107, -86, 22, -127, 3, -3, -105, -82, -7, 28, -20, 95, 0, -68, 113, -44, 64, 69, -22, 78, -103, 58, 2, -109, -75, -25, -127, 87, 34, 21, -7, -48, -30, 63, 0, -11, 91, 8, -18, -107, -21, 25, 8, -17, 79, -4, 50, 63, 91, 46, -116, 31, 6, -7, -8, -121, 62, 49, -18, 9, -10, -70, -61, 10, 38, -64, 39, 5, 127, -66, -89, 78, 50, -99, -127, 41, 18, 58, -2, -7, 106, 57, -16, -45, 101, -53, -9, -1, 66, 122, 86, -47, 16, 33, 15, -22, 32, -29, 15, 16, 40, 71, -7, 8, 30, 8, 107, 107, 0, -7, 26, 15, 34, 26, -70, -17, 98, -18, 91, -49, 126, 48, 40, -44, 17, 120, 3, -48, -32, -19, 11, -114, 4, 32, -45, -123, -111, 24, -30, -52, 116, -30, -55, 97, 8, 49, -17, 20, -104, -7, -29, 9, 23, -14, -32, 80, -126, 18, 60, 42, 107, 3, 9, -127, -17, -6, -21, -127, -18, 30, 16, 49, 104, 16, 2, 107, -42, 20, 127, 93, 127, -5, -127, -127, -9, -127, 127, 127, 127, -127, 127, 127, -127, 2, -16, -127, -127, -127, -95, 8, -127, -127, 19, 127, 127, 127, 127, 127, 127, 36, -127, 127, 39, 127, -127, 127, 127, -20, 127, -127, -127, 127, 127, -127, -127, 127, 127, -127, -41, 127, 127, -74, 127, 127, -127, 127, -65, 127, 127, 127, -11, 8, 127, -2, 127, 1, 102, -117, 127, -127, 127, 12, -127, -127, 5, -127, -127, -127, -127, 127, 114, -127, 1, -89, 127, -127, -5, 105, 127, 127, 2, 127, -127, 127, 127, -24, 127, -8, 127, -127, 127, -127, 127, 127, 60, 127, 127, -127, 31, -16, -10, -127, 127, 127, 127, -99, -127, 127, 127, 127, -29, 18, -75, 127, 127, -127, -127, 127, 113, -88, 53, 127, -127, -29, 2, 127, 127, 104, 11, 127, 127, 127, -127, -127, -114, -127, 127, -5, 127, 1, -127, -127, -127, -127, 127, 127, -127, -47, 127, 127, 127, 127, 127, 14, 127, -127, -110, 12, 127, 127, 127, 127, 127, -127, 127, 127, 127, 127, 127, -127, -8, 127, -127, 61, 127, -32, 127, -127, -127, -127, 127, -1, 127, 127, 127, 1, 120, 127, -54, -127, 3, -127, -127, -77, -127, 127, 9, -127, -127, -127, 127, 127, 127, 127, 127, -127, -24, 127, 127, 127, 17, 127, 127, 14, -127, 127, 127, -2, 127, -127, -127, 127, 38, -21, -3, -127, -127, -32, -63, 127, 5, -127, -95, -73, 98, 26, -27, -9, -31, 19, -25, 21, -42, 3, -5, 25, 122, -24, 127, 108, 11, -24, 10, 10, 49, 10, 12, 56, -26, -127, 65, 1, -121, -11, 64, 10, 8, 127, 27, 50, -22, -11, -17, -33, -67, -35, -80, -41, -121, -20, -43, -63, -23, -16, -4, 44, 89, 9, 3, 37, -105, -93, 4, 121, 5, 5, -88, -126, -7, 26, -16, -127, 2, -73, -127, -32, 60, 63, -34, 90, -106, 50, -6, -127, -66, -24, 119, 70, 38, 10, 5, -46, -36, 47, 4, -17, 82, -1, -24, -99, -13, 32, 19, -18, -110, -27, 52, 69, -127, -34, 127, 23, 10, 10, 0, -127, 56, 47, -9, 17, -9, 80, -49, 9, 29, -59, 39, -2, 109, -71, -85, 75, 51, 117, 99, 37, 13, 23, 9, 1, 98, 60, 12, -56, 93, -62, 2, 4, 39, -127, 95, -37, 22, 24, 21, -10, 24, -33, 13, 29, 37, 78, -4, 9, 42, 9, 125, -127, 12, -8, 40, 26, 42, 27, -61, -29, 117, -18, 72, -46, -127, 57, 40, -64, 27, -127, -8, -45, -25, -37, 17, -127, 5, 48, -42, 115, -97, 26, -13, -47, -127, -22, -59, 123, 25, 56, 8, 25, -107, -10, -33, 15, 29, -14, 9, 93, -127, -6, 60, 47, -127, -2, 10, 108, -13, -7, -22, 124, -16, 29, 16, 48, -125, 15, -8, -108, -45, -7, -2, 50, -5, -53, -18, 11, -15, 16, -21, -15, -2, -28, -9, -3, -15, -3, -2, -4, 3, 8, 16, 57, -61, -32, 4, 3, 9, 17, -23, -45, -45, 2, 13, -25, -17, -19, 16, -7, 10, 54, -11, 16, -5, -11, -12, -36, -12, -20, -18, 13, -29, -17, 35, -82, 0, -39, 5, -19, -14, 2, -31, -4, -42, 22, -4, 48, -27, 2, -10, -67, 4, 15, -29, 8, 12, 21, -50, 9, 15, 12, 9, 59, 24, 14, -2, 16, 6, 44, 47, 73, -47, 0, -1, -28, 12, -26, -7, -11, 17, -1, -5, -38, -16, 20, -45, -22, -23, -28, -14, 7, -31, -7, 35, 5, -5, -75, 7, -2, 1, 4, -13, 2, -9, 11, -22, 0, 8, 9, 15, 4, 55, -43, -124, 2, 6, 24, 29, -8, 3, -122, -2, -6, 13, 7, 17, 1, -13, 1, -4, 0, 21, -47, 8, -20, -4, -11, -6, -35, -9, -1, 6, -40, -27, -8, -44, 5, 6, 11, -45, -42, -1, 0, 45, -35, -8, 11, -67, -14, 7, -14, -28, -8, -54, 19, 0, -100, -46, -31, -15, 31, 4, -37, -3, 32, -7, -24, -76, 25, -88, -4, -5, 3, -52, -73, -5, 45, 14, 11, -1, 11, -34, 14, -30, 7, -8, -23, -57, 11, -3, -1, -27, 10, -25, -8, 15, 47, -1, -13, -37, 55, -23, 15, 9, -24, -25, 2, -6, -35, -16, 4, 2, 63, -5, 24, 22, 5, 23, 6, -14, -14, -4, -22, 5, 1, -16, -2, 4, -14, -21, -5, 1, -21, 42, -5, 6, -3, -4, -1, -1, -18, -2, 17, 10, -12, 6, 1, 16, 0, 4, -20, -5, -3, -6, 1, -7, 3, 31, 4, -15, 17, -17, -9, -27, -81, -9, -28, 2, -19, 1, 6, -8, -14, -27, 22, -7, -24, 6, -7, -14, -27, 0, -6, -11, -6, 7, 9, 17, -3, 10, 10, -2, 55, 31, 7, 3, 4, -2, 16, -20, -127, 1, 6, -4, -11, 5, 26, 0, 3, 4, 5, -7, 11, 1, -5, -14, -2, 19, -17, -1, 5, 12, 6, -20, 6, 11, -10, 7, -7, 15, 8, -8, 10, 5, -3, 25, -30, 1, -5, 6, -4, -71, 13, -110, -1, 4, -5, -6, -13, 4, -26, -6, -3, 1, 2, 68, -7, -15, -10, 3, -1, -6, 24, -5, -7, 0, 25, 0, -4, 2, 12, -2, 19, -19, -6, -5, -3, -8, 5, -47, 15, -9, 2, 8, -17, 8, 0, 0, 6, 17, -11, -32, 19, 18, -8, -2, -44, 24, 8, 4, 26, 3, -23, 2, 17, -3, -6, -8, -3, -38, 45, 14, 0, 22, -48, 5, 4, 1, 8, 4, 8, 7, 3, 2, 1, 1, 5, -21, -6, 3, 8, 6, -7, 1, -11, -1, 6, 4, 4, -1, -23, -10, 14, -2, 4, 16, -7, -6, 24, 12, 27, 4, -5, 8, 41, 14, -24, -44, -8, -29, -46, 2, -97, 13, 4, -29, -42, 32, 23, 123, 7, 2, -37, 44, -33, -11, 12, 12, 11, 5, 6, 68, 39, 10, -3, -2, 3, 10, 10, -3, -35, 0, -15, 7, -6, -5, -30, -71, 11, -21, -7, -45, -22, -59, -25, -56, -30, 22, -20, 5, -23, -2, -8, -93, -18, -20, -45, -6, -45, -16, -33, 15, 38, -4, 43, 9, -21, 41, 19, 19, 28, -12, 28, -43, -2, 42, -4, -12, 9, -40, 3, -4, 12, -42, -44, 3, 30, 2, 34, -1, 29, -30, 42, 11, 4, 14, -18, -1, -5, -7, 17, 8, -3, -50, 3, -37, 27, 17, -67, 13, 17, -59, -3, -34, 12, -58, 58, -3, 23, 15, 11, -39, -41, -96, -13, 8, -4, -30, 9, -33, 37, -46, 10, 33, -19, 106, -20, -21, 22, 0, -42, 19, 42, -1, -14, -82, -37, -15, 5, 30, -14, -12, 2, -2, 7, 18, -44, -17, 7, 56, 26, -15, -5, 16, -2, 22, 2, -15, -15, -27, 3, 58, 45, 33, 8, 12, -13, 25, -12, 16, 11, -5, 43, -4, -5, -7, -39, -15, -21, -50, 44, 106, 20, 46, -49, 0, 7, -26, -10, -41, 94, 2, 8, 15, 2, -19, -25, -22, -2, 3, 33, 10, -14, 6, -4, -1, 24, -17, 9, 5, -41, -37, -9, 5, -3, 24, -19, 38, 5, -12, 118, -7, 6, 37, 2, 53, -46, -30, -28, -21, -38, 46, -22, -64, 18, -36, -127, 127, -88, -48, 92, -73, -4, -89, -12, -127, 66, 11, -5, -21, 9, -18, 8, -50, -1, -127, -38, -69, 0, 35, -18, -8, 32, 55, -11, -14, -24, -75, -34, 53, 6, -65, -19, 118, -78, -1, -2, 10, 29, -103, 23, 1, 42, 51, -122, 20, -9, -24, -127, 127, -49, -4, -26, -6, -69, -12, -8, 7, 85, -70, -73, -64, 33, -127, -40, 121, -84, 18, -57, -8, 44, 11, 15, -127, -56, 13, 25, 52, 127, 79, 114, 43, 66, -29, 49, -3, -16, 83, 42, 3, -26, 2, -107, -9, 13, -15, 21, 4, -107, -43, -28, -9, 12, -108, 103, -127, 51, 23, 54, 20, 18, 1, -127, -9, -47, -16, 92, -10, 51, 46, 8, -127, 0, 110, 42, -71, 38, -34, 63, -4, -127, 44, 12, -3, -53, 86, -56, 5, -18, -62, -127, 31, 21, 37, 64, 36, -127, 22, 13, 127, -1, -28, -2, 30, 21, 56, 20, -63, 31, 27, 45, 104, 47, 7, 43, 44, -70, -28, -99, 32, -25, -29, -32, 2, -1, 60, 58, -80, 117, -92, 13, 18, 53, 6, 11, -35, -127, -18, -50, -127, -20, 104, 1, -29, 11, -5, -43, 15, 4, -40, 10, 12, 3, -119, 9, 18, 13, -23, 18, -8, -1, -16, -32, 25, -46, -127, 127, 95, 122, -42, 27, 2, -34, 0, -41, -5, -16, 24, -12, -38, 58, -5, -87, 4, 2, -33, -42, 29, 12, -43, 12, 2, 37, -1, -26, -22, 6, -30, 20, -1, -2, 64, 16, 23, 1, 7, 3, 0, 8, -2, 76, -8, -15, 18, -1, -6, -17, -29, 5, -10, -10, -109, -11, -40, -50, 45, -26, 22, 25, 7, 5, 7, -20, 123, -24, 32, 42, 19, -49, -14, -36, 18, -12, -6, -68, 9, -11, -41, 7, 22, 22, -8, -14, -42, 18, 43, -64, -8, 17, 39, 58, 6, 11, -43, -43, -4, -17, -1, 33, 4, 31, -9, 34, 1, 10, 14, -16, 1, 1, -8, 3, -28, -55, 37, 6, -37, 21, 13, -39, 4, -12, 50, 2, 1, 12, -40, -19, -4, 15, 17, -19, -17, -78, -83, -15, 10, 45, 26, 5, 73, 44, -43, 0, 39, -23, -20, 44, 127, 22, 0, -47, 23, -42, -4, -24, 62, 17, -16, 5, -38, -32, -15, -4, -10, 10, 14, -39, -10, 4, 34, -27, -18, 2, -18, -2, 12, 3, -16, 27, -50, -38, 35, -13, -32, 10, 15, 12, -18, -14, 7, 13, -7, -67, -7, -9, -2, 55, 3, 41, -49, -10, -76, 8, -36, 67, 12, 36, 88, -16, -43, -23, 16, 9, 15, 1, -9, -15, -2, -3, 10, 6, 2, 21, -43, -4, 0, -37, -32, 15, 7, 41, -34, 41, 4, -8, -30, -7, 35, 18, -11, 1, 3, -62, 1, -23, -63, 0, 3, 6, -12, 29, -7, -20, 6, 4, -16, -4, 5, -13, 3, -4, 1, 23, -8, -11, 11, -3, -11, -5, -2, -18, -8, 3, 9, -13, -24, -1, 10, -2, -3, 33, -1, -3, -8, 0, -3, -1, 6, 0, -6, 12, 20, -8, -30, -89, 12, -23, 5, 12, -18, 2, -7, -5, 43, 23, 34, 23, 6, -4, -9, -33, 3, 18, -8, 2, 6, 8, -22, -8, 10, 11, -2, -12, 35, 6, 4, -8, -2, 18, 26, 54, 7, 6, -2, -10, -2, -21, -1, 3, -4, 4, -7, -9, -3, -3, -10, -3, 15, -12, -2, 7, -10, 4, 23, 6, 10, -6, 6, -13, 12, 4, 13, 6, 2, -3, 3, 8, -3, -3, 6, 9, 16, 29, -98, 8, 3, -5, 14, -16, -36, -21, -5, 6, 12, -22, -6, 16, -15, -6, 2, -1, -2, -24, -8, 0, 3, 1, 1, -3, 23, 16, -2, -1, -19, -5, -4, -4, -14, 3, -52, -17, -9, 3, -10, -19, 3, 1, -5, -21, 23, -2, -21, -5, -21, -9, -2, -43, 5, 1, 2, 19, 0, -31, 3, 16, -1, -1, 4, 3, -59, -4, -9, 0, -23, -34, -4, 39, 9, 2, 2, 6, 0, 1, 5, 2, 0, 6, -23, -10, 2, 12, 11, -4, -3, -8, -3, 13, -30, 3, -4, 22, -9, -3, 0, 7, 3, -11, -5, 10, 9, 7, -1, -58, 7, 7, -10, -18, -6, -2, -7, 5, -8, 1, -1, 5, -13, -4, 5, 9, -8, -2, -3, -8, 8, -9, -3, 4, 11, -1, 0, -16, 19, 4, 0, -8, 5, 0, 0, 0, -19, -20, 2, -5, -3, 2, -8, -2, -5, 0, -5, 0, 0, -2, -24, -124, -4, -15, 9, 6, 16, 8, -11, 0, -3, 15, 14, -7, 4, -6, -1, 10, -6, 7, 2, 4, 4, -9, 5, -2, 2, 2, 3, 49, -2, -4, 6, -35, -1, -1, -7, -80, -3, 12, -3, -3, 0, -7, 6, 7, 9, 4, -3, 9, -2, -1, -10, -3, 4, -11, 5, 0, -6, -3, -9, -3, 4, -9, -2, 17, 5, 0, 3, 6, 7, 8, -35, -6, -2, 1, -2, -2, 1, 0, -127, -7, -1, 8, -9, -14, 10, -63, -8, 3, 4, 10, -6, 0, -3, 1, -1, -7, -9, 9, 1, -2, -9, 6, -4, -3, -3, 19, 0, -10, -8, 1, -13, -3, 15, 4, -57, -1, -8, 3, -13, -18, 12, 2, -27, 6, -11, -23, 2, 5, 9, -12, 8, -7, -4, -2, 2, -4, -9, -47, -1, -1, -5, -2, 23, -1, -39, 2, -20, 1, 7, -14, 4, 5, 1, -3, 3, -9, 0, -1, 0, 2, 4, 15, -17, -1, -9, 16, -7, 3, 15, 0, 0, 9, -10, 5, -1, -8, -6, 7, 0, -2, 7, -12, 1, 34, -1, -23, 7, -20, -1, 1, 2, -10, -6, -3, -11, -9, -9, -41, 8, 3, -20, -14, 13, 23, -7, 1, 0, -2, -15, -13, -5, 4, -14, 6, -1, -25, -2, -20, -10, -13, 10, 0, 7, 2, 7, -9, -8, -10, -2, 2, -9, -1, 0, 2, 2, -3, 37, -9, -20, -76, -10, -24, 3, 8, -7, -15, -12, -3, -17, 29, 15, -4, -4, -15, -8, -21, 16, 14, -9, 5, 6, 11, 4, -2, -3, -5, -6, -7, 28, -2, 19, 12, 5, 1, -2, -25, 6, 8, -17, -12, 3, -39, -5, 12, 1, 12, -2, -1, 0, 2, -10, -6, 19, 14, -10, -6, -9, -21, -5, 0, -10, -2, 4, -12, -1, -3, -15, 7, -7, 1, 12, 27, 2, 12, 7, 25, -5, 11, -108, -10, -3, 1, 3, -19, -18, -24, -20, -7, -2, 1, 39, 26, -36, 8, -4, -14, -5, 2, -8, 10, -9, -48, -1, -1, 19, 2, 3, -16, -18, -9, -8, -15, 7, 5, -34, -7, -1, 4, 2, -18, -1, 0, -13, 0, -11, 5, -14, -4, 4, -2, -1, -32, -24, -9, 8, 7, -10, -14, -2, 9, 2, -5, -6, -3, -29, -20, 29, 4, 3, -54, -4, -6, -2, -11, -12, 19, 18, 1, 3, 2, -10, -10, -23, -5, 18, 23, 5, 5, -10, -4, 0, 20, -30, -8, 0, -2, -10, -5, 1, -12, -11, 2, 12, 24, 8, -4, -12, 18, 8, -5, -11, 5, -5, 0, -22, -18, -6, -69, -3, 0, -16, -31, 36, -68, -76, -2, -16, -2, -15, -35, -15, -17, 1, -21, -25, -24, -49, -2, -3, -16, -3, -19, 0, -2, -12, -8, -6, 17, 17, -10, -17, -19, -18, -19, -7, 14, -62, -22, 31, -84, -2, -39, 4, 3, -1, -5, -30, -3, 50, 29, 13, -6, 9, -35, 23, -127, -12, -1, -12, -20, 15, -17, -1, -3, -2, -10, 25, -19, 25, 4, 37, -72, -13, 10, -2, -52, 5, 7, -33, -34, 3, 6, 0, 21, 40, 38, -8, 6, -26, 16, -46, -16, 18, -13, 5, 0, 6, 6, -5, 11, 16, -73, -1, -6, 14, -19, -21, -8, -6, 18, -41, -20, -3, 10, 9, -4, 22, -37, -81, -1, 6, 13, -1, -11, -26, -106, -42, -10, 32, 6, 6, 13, -85, 4, -3, -38, 42, -2, 10, -12, 4, 33, -8, -30, 27, 11, 2, 6, -19, 2, -36, -28, 2, 12, -47, 9, -25, 2, 19, -30, 3, 9, -61, -40, 68, -20, -11, 19, -6, -7, 2, -81, 13, -17, 8, 70, -9, -69, -4, 3, 3, -14, -25, 25, -83, 27, 16, 11, 1, -103, -14, -5, 0, 2, -18, 5, 31, -1, -35, 7, -27, -32, -56, 5, 0, 3, 1, -1, -15, -3, 0, 8, -26, 12, -36, 4, -27, 2, 9, -13, -33, 44, 23, 6, -16, 7, 5, 6, -3, -3, 8, 1, -1, -5, -10, 13, 1, -32, 6, 1, -15, -13, 14, 19, -40, -3, 0, 1, -50, -18, -6, -2, 10, 9, -2, -20, -7, 15, -3, -12, -26, -2, 3, 6, 8, 30, 3, -6, 1, 2, -9, -7, 28, -1, 3, 2, -9, -12, -21, -69, 12, -22, 2, -33, -3, 24, -7, -8, 49, 29, -19, 9, -23, -16, -6, -19, 14, -1, -7, 4, 6, 10, -1, 4, -2, -9, -2, 22, 31, -5, 17, 5, 6, 0, 4, -10, -11, 8, -19, -15, 6, 11, 1, 17, -6, 14, -2, 7, -1, -1, -11, -8, -21, -15, -10, -2, 13, 12, 1, 1, -11, 0, 8, -4, -7, 4, 19, 14, -8, -4, -4, -8, 1, 9, 4, -12, -16, 5, -103, -17, 1, -4, -4, -20, 34, -35, -20, -3, 10, -15, -4, -4, -14, 9, -5, -19, 0, -3, -5, 2, 2, 11, -4, -4, -68, 6, -1, 8, -19, -3, -12, -17, 6, 4, -32, 6, -1, 5, -5, -10, 3, 1, -10, 9, -17, -2, -1, 22, -4, -4, -3, -30, -5, 6, 6, -1, -8, -28, 1, 9, -6, -3, -4, 1, -54, 12, -8, 9, -3, 3, -2, 13, 15, -5, -15, -5, 27, 5, 1, 2, -16, -10, -16, -4, 19, 12, 3, -18, 7, -12, -2, -12, 5, -5, -3, 6, -10, 15, 1, -9, -2, 12, 14, -5, 5, -1, 0, -5, 8, -9, 24, -17, 11, -1, -4, 4, -11, -9, 2, 1, -8, -3, 2, 11, -2, 1, -3, 6, 4, -4, 3, 7, 4, -4, 0, -19, 18, -3, 2, -10, -19, -3, 0, 2, -10, 19, -1, -3, -2, 3, -9, -4, 3, 0, -7, -4, -6, -2, -21, -102, -6, -20, 7, -3, -19, -4, -14, 9, -5, 17, 5, 7, 3, -10, 1, 7, -10, 1, 2, -6, 3, -10, -6, 2, 3, 3, 3, -14, -3, -5, 6, 1, -2, 2, 8, 73, -2, 12, -6, -6, 0, 2, -7, 4, 18, 5, -27, 11, -1, -3, -9, -4, 12, 0, 7, 1, -6, -3, 11, -2, 2, -10, -3, 12, 3, -5, -1, 12, -5, -11, 5, 3, -1, 0, -1, 3, -44, -28, -124, -6, -2, -12, 2, -12, -9, -57, -6, 0, 6, 1, 2, 10, 1, 6, 3, -8, -8, -12, 0, 0, -6, -5, -6, -4, 19, 18, 1, 2, -9, 1, -17, 1, 14, 3, -61, -9, -6, 2, -5, -23, 7, 0, -32, 7, -12, -1, -4, 0, -5, -16, 6, -14, 5, 9, 2, -2, -12, -1, -3, 3, 4, -2, 25, -1, -21, 19, 0, -2, -10, -59, -2, 15, -10, -4, 0, 2, 3, -3, 0, 1, 7, 16, -19, 0, -7, 18, -8, 11, 14, -3, 0, -16, 13, 3, 0, 8, -6, 8, 1, 5, 15, -13, 0, -9, 2};

float bias_raw[240]={-0.8052746653556824, -0.8859439492225647, -2.4354934692382812, -1.7227659225463867, -0.3769914507865906, 1.2317938804626465, 2.093571424484253, -1.2167549133300781, 5.0756940841674805, -0.6345250606536865, -1.8672794103622437, -1.826467514038086, 0.3055537939071655, -0.7910257577896118, -2.721099615097046, -0.4214954376220703, -0.4014706313610077, -0.3406144380569458, 1.3047316074371338, 1.118876338005066, -0.8575014472007751, 1.5219957828521729, -0.5531800985336304, -0.5107417702674866, 1.904035210609436, -0.8701920509338379, -3.124004364013672, -0.4722309708595276, -5.906487464904785, 0.5470054745674133, 0.49536949396133423, -2.2966532707214355, -1.1571142673492432, -0.8031089305877686, 0.6546863317489624, -0.7088973522186279, 1.1802526712417603, -0.4126124382019043, -3.705768585205078, 0.9575744867324829, -1.4981273412704468, -0.2867926359176636, 0.4437221586704254, 1.6716244220733643, 1.2224535942077637, 1.00331449508667, 2.4230451583862305, 2.6313371658325195, 0.16212046146392822, -0.26623672246932983, 0.7699954509735107, 1.0730485916137695, 0.9207095503807068, -0.6517227292060852, 1.9841194152832031, -1.7906510829925537, -0.06023001670837402, 0.6319141387939453, -2.049482583999634, -1.1490542888641357, -0.5466915369033813, 0.6208328604698181, -1.2184756994247437, -0.12559804320335388, -0.35759755969047546, -1.761790156364441, -0.5484040379524231, -2.125480890274048, -0.5664777159690857, 0.648048996925354, 0.14616918563842773, -3.5904808044433594, -1.0198159217834473, 0.8251276016235352, -1.025588035583496, -1.6562749147415161, 1.8204843997955322, -0.6701618432998657, -1.1573052406311035, -0.9727960824966431, -0.32332655787467957, 1.3899363279342651, -4.501889705657959, 0.9624089002609253, 0.5596763491630554, -0.41102826595306396, 1.2415361404418945, -0.9415320754051208, -2.2875680923461914, -0.5686750411987305, -5.480710029602051, -0.6537845134735107, 0.14092206954956055, -0.41547438502311707, 2.3460628986358643, 3.3816699981689453, -2.738691806793213, -0.5869685411453247, -0.576506495475769, -3.7999041080474854, -0.5361034274101257, -1.7999275922775269, -0.38329264521598816, 1.1673611402511597, -1.0300023555755615, 1.4404187202453613, 1.707669734954834, -1.5085383653640747, -1.5436060428619385, -0.6468616127967834, -1.1573172807693481, -0.8591535687446594, -0.5030535459518433, -0.5474489331245422, -1.1672186851501465, -0.22046615183353424, 0.9809820652008057, 2.6607916355133057, 4.872330188751221, -1.0056374073028564, 0.05645251274108887, -1.2179412841796875, -4.7958173751831055, -0.3970973789691925, -0.3948560953140259, 1.393532633781433, -2.7670249938964844, -2.0729148387908936, -0.9958550333976746, -0.808254599571228, -1.0276331901550293, -2.0864524841308594, 1.3798925876617432, 1.5962579250335693, -1.061992883682251, 0.8223468065261841, -0.6423848271369934, -0.1959051787853241, -0.6390955448150635, -2.589561939239502, 1.0594184398651123, -0.5248591303825378, -0.47720015048980713, -1.7122310400009155, -0.7428820729255676, 1.2460652589797974, -0.7473303079605103, 1.0470733642578125, -0.6218551397323608, -0.5696331262588501, -0.5461912155151367, -0.7338453531265259, -0.5355017185211182, 1.4339416027069092, 2.222825765609741, -1.5292677879333496, 1.835841178894043, 0.9043397903442383, 1.3637115955352783, 1.4737966060638428, 0.465997576713562, -0.8191509246826172, -1.5806124210357666, -0.22982625663280487, -4.0870795249938965, 0.8875710964202881, -0.8064620494842529, -0.9975857734680176, -0.821878969669342, 0.8881747722625732, -0.7696893215179443, 1.0456708669662476, 0.5163462162017822, 0.09281307458877563, 1.0652714967727661, -2.3790273666381836, -0.28230488300323486, 2.5815048217773438, -1.7878671884536743, -1.2619584798812866, -1.4578193426132202, 2.0080361366271973, -1.1517934799194336, -0.4467334747314453, -1.8274046182632446, -1.5033185482025146, 0.8748834729194641, -2.4498484134674072, -0.531704306602478, 1.561148762702942, 0.1261235773563385, 2.093794345855713, 3.101339817047119, 0.5424889326095581, 0.6264629364013672, -0.08995115756988525, -1.6718723773956299, 2.270395278930664, -0.5627883672714233, 0.9165690541267395, -2.188406467437744, 1.0044575929641724, -1.0664994716644287, -0.46571627259254456, 1.830885410308838, 4.383548259735107, 0.20643919706344604, -1.11060631275177, -1.5918605327606201, -0.8302484750747681, -0.8171553611755371, 1.5198003053665161, 1.3420164585113525, 1.1565805673599243, -0.057535141706466675, -0.1923316866159439, 1.3395758867263794, -0.7825930714607239, 1.3730746507644653, 1.5661566257476807, -4.131626129150391, -0.26995670795440674, -0.9005345702171326, -0.3188006579875946, -1.9850670099258423, -0.8000200986862183, -2.3164620399475098, -1.2577061653137207, -5.666134834289551, 1.0835955142974854, -0.5433042049407959, -0.5214581489562988, -1.0091251134872437, -0.8273630738258362, -0.4466891884803772, -0.8227184414863586, -1.7331950664520264, 0.03187292814254761, -3.0015430450439453, 2.2552058696746826};

int8_t* filter_tensor_data=filter_raw;
float* bias_tensor_data=bias_raw;

bool has_conv_bias=true;
int stride_width=1;
int stride_height=1;
TfLiteFusedActivation activation=kTfLiteActNone;
int dilation_width_factor=1;
int dilation_height_factor=1;
const int filter_dims_size=4;
const int filter_dims_raw[4]={1,5,5,240};
const int bias_dims_size=1;
const int32_t bias_dims_raw[1]={240};
TfLitePadding paddings=kTfLitePaddingSame;
TfLiteType filter_type=kTfLiteInt8;
TfLiteType bias_type=kTfLiteFloat32;
const float scale_filter=0.0;
const int32_t zero_point_filter=0;
const float scale_bias=0.0;
const int32_t zero_point_bias=0;

struct OpData {
  TfLitePaddingValues padding;
  // The scaling factor from input to output (aka the 'real multiplier') can
  // be represented as a fixed point multiplier plus a left shift.
  int32_t output_multiplier;
  int output_shift;
  // The range of the fused activation layer. For example for kNone and
  // uint8_t these would be 0 and 255.
  int32_t output_activation_min;
  int32_t output_activation_max;

  // Per channel output multiplier and shift.
  std::vector<int32_t> per_channel_output_multiplier;
  std::vector<int> per_channel_output_shift;

  // Hybrid per channel temporary tensors.
  int input_quantized_id = kTensorNotAllocated;
  int scaling_factors_id = kTensorNotAllocated;
  int input_offset_id = kTensorNotAllocated;
  int32_t input_quantized_index;
  int32_t scaling_factors_index;
  int32_t input_offset_index;
};

void ExtractDepthConvParams(TfLitePadding padding, int stride_width, int stride_height,
                               int dilation_width_factor, int dilation_height_factor,
                               TfLiteFusedActivation activation,
                               TfLiteDepthwiseConvParams* data_params) {
  // TfLiteDepthwiseConvParams data_params;
  data_params->padding = padding;
  data_params->stride_width = stride_width;
  data_params->stride_height = stride_height;
  data_params->dilation_width_factor = dilation_width_factor;
  data_params->dilation_height_factor = dilation_height_factor;
  data_params->activation = activation;
  // return data_params;
}

void GetDepthConvTensor(TfLiteType type, const char* name, TfLiteIntArray* tensor_dims_data, 
                       TfLiteQuantizationParams quant_params, char* tensor_data,
                       TfLiteAffineQuantization* quant_struct, size_t bytes_size,
                       TfLiteTensor* tensor) {
  tensor->type = type;
  tensor->name = name;
  tensor->dims = tensor_dims_data;
  tensor->params = quant_params;
  // tensor->data.raw = reinterpret_cast<char*>(tensor_data);
  tensor->data.raw = tensor_data;
  tensor->bytes = bytes_size;
  tensor->allocation_type = kTfLiteMemNone;
  // data_0.allocation = allocation;
  tensor->is_variable = false;
  if (type != kTfLiteFloat32) {
    tensor->quantization.type = kTfLiteAffineQuantization;
    tensor->quantization.params = quant_struct;
  } else {
    tensor->quantization.type = kTfLiteNoQuantization;
  }
  tensor->sparsity = nullptr;
}
void* Init(TfLiteContext* context, const char* buffer, size_t length) {
  // This is a builtin op, so we don't use the contents in 'buffer', if any.
  // Instead, we allocate a new object to carry information from Prepare() to
  // Eval().
  return new OpData;
}

void Free(TfLiteContext* context, void* buffer) {
  delete reinterpret_cast<OpData*>(buffer);
}

TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
  // auto* params =
  //     reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);
  TfLiteDepthwiseConvParams data_params;
  ExtractDepthConvParams(paddings, stride_width, stride_height, dilation_width_factor, dilation_height_factor, activation, &data_params);
  TfLiteDepthwiseConvParams* params = &data_params;

  OpData* data = reinterpret_cast<OpData*>(node->user_data);

  bool has_bias = false;

  // TF_LITE_ENSURE(context, has_bias || NumInputs(node) == 2);
  const TfLiteTensor* input;
  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));
  TfLiteTensor filter_tensor;
  TfLiteIntArray* filter_dims_data = TfLiteIntArrayCreate(filter_dims_size);
  int size_filter = 1;
  for (int i = 0; i < filter_dims_size; i++) {
    // std::cout << "dims_raw: " << dims_raw[i] << std::endl;
    filter_dims_data->data[i] = filter_dims_raw[i];
    size_filter *= filter_dims_raw[i];
  }
  size_t bytes_size_filter = sizeof(float) * size_filter;
  TfLiteQuantizationParams filter_params;
  filter_params.scale=scale_filter;
  filter_params.zero_point=zero_point_filter;
  TfLiteFloatArray* scale_array_filter = TfLiteFloatArrayCreate(1);
  scale_array_filter->data[0] = scale_filter;
  TfLiteIntArray* zero_point_array_filter = TfLiteIntArrayCreate(1);
  zero_point_array_filter->data[0] = zero_point_filter;

  TfLiteAffineQuantization quant_struct_filter;
  quant_struct_filter.scale = scale_array_filter;
  quant_struct_filter.zero_point = zero_point_array_filter;
  quant_struct_filter.quantized_dimension = 0;
  // float* filter_data;
  // filter_tensor_data = filter_raw;
  GetDepthConvTensor(filter_type, "filter", filter_dims_data, filter_params,
                       reinterpret_cast<char*>(filter_tensor_data),
                       &quant_struct_filter, bytes_size_filter, &filter_tensor);
  const TfLiteTensor* filter = &filter_tensor;
  // TF_LITE_ENSURE_OK(context,
  //                   GetInputSafe(context, node, kFilterTensor, &filter));
  const TfLiteTensor* bias = nullptr;

  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
  TfLiteTensor* output;
  TF_LITE_ENSURE_OK(context,
                    GetOutputSafe(context, node, kOutputTensor, &output));

  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);
  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);
  TF_LITE_ENSURE(context, params->dilation_height_factor > 0);
  TF_LITE_ENSURE(context, params->dilation_width_factor > 0);

  const TfLiteType data_type = input->type;

  const TfLiteType filter_type = filter->type;
  const bool is_hybrid =
      data_type == kTfLiteFloat32 && filter_type == kTfLiteInt8;
  TF_LITE_ENSURE(context,
                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||
                     data_type == kTfLiteInt8 || data_type == kTfLiteInt16);
  TF_LITE_ENSURE_TYPES_EQ(context, output->type, data_type);
  if (!is_hybrid) {
    TF_LITE_ENSURE(context,
                   filter->type == data_type || data_type == kTfLiteInt16);
  }

  if (data_type == kTfLiteInt16) {
    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);
    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);
  }

  // Filter in DepthwiseConv is expected to be [1, H, W, O].
  TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 0), 1);

  if (has_bias) {
    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));
    if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {
      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);
      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);
    } else if (data_type == kTfLiteInt16) {
      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);
      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);
    } else {
      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, data_type);
    }
    TF_LITE_ENSURE_EQ(context, NumDimensions(bias), 1);
    TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 3),
                      SizeOfDimension(bias, 0));
  }

  int channels_out = SizeOfDimension(filter, 3);
  int width = SizeOfDimension(input, 2);
  int height = SizeOfDimension(input, 1);
  int filter_width = SizeOfDimension(filter, 2);
  int filter_height = SizeOfDimension(filter, 1);
  int batches = SizeOfDimension(input, 0);

  // Matching GetWindowedOutputSize in TensorFlow.
  auto padding = params->padding;
  int out_width, out_height;

  data->padding = ComputePaddingHeightWidth(
      params->stride_height, params->stride_width,
      params->dilation_height_factor, params->dilation_width_factor, height,
      width, filter_height, filter_width, padding, &out_height, &out_width);

  // Note that quantized inference requires that all tensors have their
  // parameters set. This is usually done during quantized training or
  // calibration.
  if (data_type != kTfLiteFloat32) {
    TF_LITE_ENSURE_EQ(context, filter->quantization.type,
                      kTfLiteAffineQuantization);
    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);
    const auto* affine_quantization =
        reinterpret_cast<TfLiteAffineQuantization*>(
            filter->quantization.params);
    TF_LITE_ENSURE(context, affine_quantization);
    TF_LITE_ENSURE(context, affine_quantization->scale);
    TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||
                             affine_quantization->scale->size == channels_out));

    data->per_channel_output_multiplier.resize(channels_out);
    data->per_channel_output_shift.resize(channels_out);
    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(
        context, input, filter, bias, output, params->activation,
        &data->output_multiplier, &data->output_shift,
        &data->output_activation_min, &data->output_activation_max,
        data->per_channel_output_multiplier.data(),
        data->per_channel_output_shift.data(), channels_out));
  }

  if (is_hybrid) {
    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);
    const auto* affine_quantization =
        reinterpret_cast<TfLiteAffineQuantization*>(
            filter->quantization.params);
    TF_LITE_ENSURE(context, affine_quantization);
    TF_LITE_ENSURE(context, affine_quantization->scale);
    TF_LITE_ENSURE_EQ(
        context, affine_quantization->scale->size,
        filter->dims->data[affine_quantization->quantized_dimension]);

    int temporaries_count = 0;
    data->input_quantized_index = temporaries_count;
    if (data->input_quantized_id == kTensorNotAllocated) {
      TF_LITE_ENSURE_OK(
          context, context->AddTensors(context, 1, &data->input_quantized_id));
    }
    ++temporaries_count;
    data->scaling_factors_index = temporaries_count;
    if (data->scaling_factors_id == kTensorNotAllocated) {
      TF_LITE_ENSURE_OK(
          context, context->AddTensors(context, 1, &data->scaling_factors_id));
    }
    ++temporaries_count;
    data->input_offset_index = temporaries_count;
    if (data->input_offset_id == kTensorNotAllocated) {
      TF_LITE_ENSURE_OK(
          context, context->AddTensors(context, 1, &data->input_offset_id));
    }
    ++temporaries_count;

    TfLiteIntArrayFree(node->temporaries);
    node->temporaries = TfLiteIntArrayCreate(temporaries_count);

    node->temporaries->data[data->input_quantized_index] =
        data->input_quantized_id;
    TfLiteTensor* input_quantized;
    TF_LITE_ENSURE_OK(
        context, GetTemporarySafe(context, node, data->input_quantized_index,
                                  &input_quantized));
    input_quantized->type = kTfLiteInt8;
    input_quantized->allocation_type = kTfLiteArenaRw;
    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {
      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);
      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,
                                                       input_quantized_size));
    }
    node->temporaries->data[data->scaling_factors_index] =
        data->scaling_factors_id;
    TfLiteTensor* scaling_factors;
    TF_LITE_ENSURE_OK(
        context, GetTemporarySafe(context, node, data->scaling_factors_index,
                                  &scaling_factors));
    scaling_factors->type = kTfLiteFloat32;
    scaling_factors->allocation_type = kTfLiteArenaRw;
    const int batch_size = SizeOfDimension(input, 0);
    int scaling_dims[1] = {batch_size};
    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {
      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);
      scaling_factors_size->data[0] = batch_size;
      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,
                                                       scaling_factors_size));
    }
    node->temporaries->data[data->input_offset_index] = data->input_offset_id;
    TfLiteTensor* input_offsets;
    TF_LITE_ENSURE_OK(context,
                      GetTemporarySafe(context, node, data->input_offset_index,
                                       &input_offsets));
    input_offsets->type = kTfLiteInt32;
    input_offsets->allocation_type = kTfLiteArenaRw;
    if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {
      TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);
      input_offsets_size->data[0] = batch_size;
      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,
                                                       input_offsets_size));
    }
  }

  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(4);
  outputSize->data[0] = batches;
  outputSize->data[1] = out_height;
  outputSize->data[2] = out_width;
  outputSize->data[3] = channels_out;
  return context->ResizeTensor(context, output, outputSize);
}

TfLiteStatus ComputeDepthMultiplier(TfLiteContext* context,
                                    const TfLiteTensor* input,
                                    const TfLiteTensor* filter,
                                    int16* depth_multiplier) {
  int num_filter_channels = SizeOfDimension(filter, 3);
  int num_input_channels = SizeOfDimension(input, 3);
  TF_LITE_ENSURE(context, num_input_channels != 0);
  TF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);
  *depth_multiplier = num_filter_channels / num_input_channels;
  return kTfLiteOk;
}

template <KernelType kernel_type>
TfLiteStatus EvalFloat(TfLiteContext* context, TfLiteNode* node,
                       TfLiteDepthwiseConvParams* params, OpData* data,
                       const TfLiteTensor* input, const TfLiteTensor* filter,
                       const TfLiteTensor* bias, TfLiteTensor* output) {
  float output_activation_min, output_activation_max;
  CalculateActivationRange(params->activation, &output_activation_min,
                           &output_activation_max);

  DepthwiseParams op_params;
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;
  TF_LITE_ENSURE_STATUS(ComputeDepthMultiplier(context, input, filter,
                                               &op_params.depth_multiplier));
  if (kernel_type == kReference) {
    reference_ops::DepthwiseConv(
        op_params, GetTensorShape(input), GetTensorData<float>(input),
        GetTensorShape(filter), GetTensorData<float>(filter),
        GetTensorShape(bias), GetTensorData<float>(bias),
        GetTensorShape(output), GetTensorData<float>(output));
  } else {
    optimized_ops::DepthwiseConv<float, float>(
        op_params, GetTensorShape(input), GetTensorData<float>(input),
        GetTensorShape(filter), GetTensorData<float>(filter),
        GetTensorShape(bias), GetTensorData<float>(bias),
        GetTensorShape(output), GetTensorData<float>(output),
        CpuBackendContext::GetFromContext(context));
  }
  return kTfLiteOk;
}

template <KernelType kernel_type>
TfLiteStatus EvalQuantized(TfLiteContext* context, TfLiteNode* node,
                           TfLiteDepthwiseConvParams* params, OpData* data,
                           const TfLiteTensor* input,
                           const TfLiteTensor* filter, const TfLiteTensor* bias,
                           TfLiteTensor* output) {
  auto input_offset = -input->params.zero_point;
  auto filter_offset = -filter->params.zero_point;
  auto output_offset = output->params.zero_point;

  DepthwiseParams op_params;
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.input_offset = input_offset;
  op_params.weights_offset = filter_offset;
  op_params.output_offset = output_offset;
  op_params.output_multiplier = data->output_multiplier;
  op_params.output_shift = -data->output_shift;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  TF_LITE_ENSURE_STATUS(ComputeDepthMultiplier(context, input, filter,
                                               &op_params.depth_multiplier));
  if (kernel_type == kReference) {
    reference_ops::DepthwiseConv(
        op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
        GetTensorShape(filter), GetTensorData<uint8_t>(filter),
        GetTensorShape(bias), GetTensorData<int32_t>(bias),
        GetTensorShape(output), GetTensorData<uint8_t>(output));
  } else {
    optimized_ops::DepthwiseConv<uint8, int32>(
        op_params, GetTensorShape(input), GetTensorData<uint8_t>(input),
        GetTensorShape(filter), GetTensorData<uint8_t>(filter),
        GetTensorShape(bias), GetTensorData<int32_t>(bias),
        GetTensorShape(output), GetTensorData<uint8_t>(output),
        CpuBackendContext::GetFromContext(context));
  }
  return kTfLiteOk;
}

template <KernelType kernel_type>
TfLiteStatus EvalQuantizedPerChannel(TfLiteContext* context, TfLiteNode* node,
                                     TfLiteDepthwiseConvParams* params,
                                     OpData* data, const TfLiteTensor* input,
                                     const TfLiteTensor* filter,
                                     const TfLiteTensor* bias,
                                     TfLiteTensor* output) {
  DepthwiseParams op_params;
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.input_offset = -input->params.zero_point;
  op_params.weights_offset = 0;
  op_params.output_offset = output->params.zero_point;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;
  TF_LITE_ENSURE_STATUS(ComputeDepthMultiplier(context, input, filter,
                                               &op_params.depth_multiplier));

  if (kernel_type == kReference) {
    reference_integer_ops::DepthwiseConvPerChannel(
        op_params, data->per_channel_output_multiplier.data(),
        data->per_channel_output_shift.data(), GetTensorShape(input),
        GetTensorData<int8>(input), GetTensorShape(filter),
        GetTensorData<int8>(filter), GetTensorShape(bias),
        GetTensorData<int32>(bias), GetTensorShape(output),
        GetTensorData<int8>(output));
  } else {
    optimized_integer_ops::DepthwiseConvPerChannel(
        op_params, data->per_channel_output_multiplier.data(),
        data->per_channel_output_shift.data(), GetTensorShape(input),
        GetTensorData<int8>(input), GetTensorShape(filter),
        GetTensorData<int8>(filter), GetTensorShape(bias),
        GetTensorData<int32>(bias), GetTensorShape(output),
        GetTensorData<int8>(output),
        CpuBackendContext::GetFromContext(context));
  }
  return kTfLiteOk;
}

TfLiteStatus EvalQuantizedPerChannel16x8(
    const TfLiteDepthwiseConvParams* params, const OpData* data,
    const TfLiteTensor* input, const TfLiteTensor* filter,
    const TfLiteTensor* bias, TfLiteTensor* output) {
  DepthwiseParams op_params;
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.depth_multiplier = params->depth_multiplier;
  op_params.weights_offset = 0;
  op_params.quantized_activation_min = data->output_activation_min;
  op_params.quantized_activation_max = data->output_activation_max;

  reference_integer_ops::DepthwiseConvPerChannel(
      op_params, data->per_channel_output_multiplier.data(),
      data->per_channel_output_shift.data(), GetTensorShape(input),
      GetTensorData<int16>(input), GetTensorShape(filter),
      GetTensorData<int8>(filter), GetTensorShape(bias),
      GetTensorData<std::int64_t>(bias), GetTensorShape(output),
      GetTensorData<int16>(output));

  return kTfLiteOk;
}

template <KernelType kernel_type>
TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,
                                  TfLiteDepthwiseConvParams* params,
                                  OpData* data, const TfLiteTensor* input,
                                  const TfLiteTensor* filter,
                                  const TfLiteTensor* bias,
                                  TfLiteTensor* output) {
  float output_activation_min, output_activation_max;
  CalculateActivationRange(params->activation, &output_activation_min,
                           &output_activation_max);
  const int batch_size = SizeOfDimension(input, 0);
  TF_LITE_ENSURE(context, batch_size != 0);
  const int input_size = NumElements(input) / batch_size;
  TfLiteTensor* input_quantized;
  TF_LITE_ENSURE_OK(context,
                    GetTemporarySafe(context, node, data->input_quantized_index,
                                     &input_quantized));
  int8_t* quantized_input_ptr_batch = input_quantized->data.int8;
  TfLiteTensor* scaling_factors_tensor;
  TF_LITE_ENSURE_OK(context,
                    GetTemporarySafe(context, node, data->scaling_factors_index,
                                     &scaling_factors_tensor));
  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);
  TfLiteTensor* input_offset_tensor;
  TF_LITE_ENSURE_OK(context,
                    GetTemporarySafe(context, node, data->input_offset_index,
                                     &input_offset_tensor));
  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);

  for (int b = 0; b < batch_size; ++b) {
    const int offset = b * input_size;
    tensor_utils::AsymmetricQuantizeFloats(
        GetTensorData<float>(input) + offset, input_size,
        quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],
        &input_offset_ptr[b]);
  }

  DepthwiseParams op_params;
  op_params.padding_type = PaddingType::kSame;
  op_params.padding_values.width = data->padding.width;
  op_params.padding_values.height = data->padding.height;
  op_params.stride_width = params->stride_width;
  op_params.stride_height = params->stride_height;
  op_params.dilation_width_factor = params->dilation_width_factor;
  op_params.dilation_height_factor = params->dilation_height_factor;
  op_params.depth_multiplier = params->depth_multiplier;

  op_params.weights_offset = 0;
  op_params.float_activation_min = output_activation_min;
  op_params.float_activation_max = output_activation_max;
  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);
  const auto* affine_quantization =
      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);
  if (kernel_type == kReference) {
    reference_integer_ops::DepthwiseConvHybridPerChannel(
        op_params, scaling_factors_ptr, GetTensorShape(input),
        quantized_input_ptr_batch, GetTensorShape(filter),
        GetTensorData<int8>(filter), GetTensorShape(bias),
        GetTensorData<float>(bias), GetTensorShape(output),
        GetTensorData<float>(output), affine_quantization->scale->data,
        input_offset_ptr);
  } else {
    optimized_integer_ops::DepthwiseConvHybridPerChannel(
        op_params, scaling_factors_ptr, GetTensorShape(input),
        quantized_input_ptr_batch, GetTensorShape(filter),
        GetTensorData<int8>(filter), GetTensorShape(bias),
        GetTensorData<float>(bias), GetTensorShape(output),
        GetTensorData<float>(output), affine_quantization->scale->data,
        input_offset_ptr, CpuBackendContext::GetFromContext(context));
  }

  return kTfLiteOk;
}

template <KernelType kernel_type, TfLiteType input_type>
TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node) {
  // auto* params =
  //     reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);
  TfLiteDepthwiseConvParams data_params;
  ExtractDepthConvParams(paddings, stride_width, stride_height, dilation_width_factor, dilation_height_factor, activation, &data_params);
  TfLiteDepthwiseConvParams* params = &data_params;

  OpData* data = reinterpret_cast<OpData*>(node->user_data);

  TfLiteTensor* output;
  TF_LITE_ENSURE_OK(context,
                    GetOutputSafe(context, node, kOutputTensor, &output));
  const TfLiteTensor* input;
  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));
  // const TfLiteTensor* filter;
  // TF_LITE_ENSURE_OK(context,
  //                   GetInputSafe(context, node, kFilterTensor, &filter));
  TfLiteTensor filter_tensor;
  TfLiteIntArray* filter_dims_data = TfLiteIntArrayCreate(filter_dims_size);
  int size_filter = 1;
  for (int i = 0; i < filter_dims_size; i++) {
    // std::cout << "dims_raw: " << dims_raw[i] << std::endl;
    filter_dims_data->data[i] = filter_dims_raw[i];
    size_filter *= filter_dims_raw[i];
  }
  size_t bytes_size_filter = sizeof(float) * size_filter;
  TfLiteQuantizationParams filter_params;
  filter_params.scale=scale_filter;
  filter_params.zero_point=zero_point_filter;

  TfLiteFloatArray* scale_array_filter = TfLiteFloatArrayCreate(1);
  scale_array_filter->data[0] = scale_filter;
  TfLiteIntArray* zero_point_array_filter = TfLiteIntArrayCreate(1);
  zero_point_array_filter->data[0] = zero_point_filter;

  TfLiteAffineQuantization quant_struct_filter;
  quant_struct_filter.scale = scale_array_filter;
  quant_struct_filter.zero_point = zero_point_array_filter;
  quant_struct_filter.quantized_dimension = 0;
  // float* filter_data;
  // filter_tensor_data = filter_raw;
  GetDepthConvTensor(filter_type, "filter", filter_dims_data, filter_params,
                       reinterpret_cast<char*>(filter_tensor_data),
                       &quant_struct_filter, bytes_size_filter, &filter_tensor);
  const TfLiteTensor* filter = &filter_tensor;
  // const TfLiteTensor* bias =
  //     (NumInputs(node) == 3) ? GetInput(context, node, kBiasTensor) : nullptr;
  TfLiteTensor bias_tensor;
  const TfLiteTensor* bias;
  if (has_conv_bias) {
    TfLiteIntArray* bias_dims_data = TfLiteIntArrayCreate(bias_dims_size);
    int size_bias = 1;
    for (int i = 0; i < bias_dims_size; i++) {
      // std::cout << "dims_raw: " << dims_raw[i] << std::endl;
      bias_dims_data->data[i] = bias_dims_raw[i];
      size_bias *= bias_dims_raw[i];
    }
    size_t bytes_size_bias = sizeof(float) * size_bias;
    TfLiteQuantizationParams bias_params;
    bias_params.scale=scale_bias;
    bias_params.zero_point=zero_point_bias;

    TfLiteFloatArray* scale_array_bias = TfLiteFloatArrayCreate(1);
    scale_array_bias->data[0] = scale_bias;
    TfLiteIntArray* zero_point_array_bias = TfLiteIntArrayCreate(1);
    zero_point_array_bias->data[0] = zero_point_bias;

    TfLiteAffineQuantization quant_struct_bias;
    quant_struct_bias.scale = scale_array_bias;
    quant_struct_bias.zero_point = zero_point_array_bias;
    quant_struct_bias.quantized_dimension = 0;
    
    // float* bias_data;
    // bias_tensor_data = bias_raw;
    GetDepthConvTensor(bias_type, "bias", bias_dims_data, bias_params,
                        reinterpret_cast<char*>(bias_tensor_data), 
                        &quant_struct_bias, bytes_size_bias, &bias_tensor);
    bias = &bias_tensor;
  } else {
    bias = nullptr;
  }

  TFLITE_DCHECK_EQ(input_type, input->type);

  switch (input_type) {  // Already know in/out types are same.
    case kTfLiteFloat32:
      if (filter->type == kTfLiteFloat32) {
        return EvalFloat<kernel_type>(context, node, params, data, input,
                                      filter, bias, output);
      } else if (filter->type == kTfLiteInt8) {
        return EvalHybridPerChannel<kernel_type>(context, node, params, data,
                                                 input, filter, bias, output);
      } else {
        TF_LITE_KERNEL_LOG(
            context, "Type %s with filter type %s not currently supported.",
            TfLiteTypeGetName(input->type), TfLiteTypeGetName(filter->type));
        return kTfLiteError;
      }
      break;
    case kTfLiteUInt8:
      return EvalQuantized<kernel_type>(context, node, params, data, input,
                                        filter, bias, output);
      break;
    case kTfLiteInt8:
      return EvalQuantizedPerChannel<kernel_type>(context, node, params, data,
                                                  input, filter, bias, output);
      break;
    case kTfLiteInt16:
      return EvalQuantizedPerChannel16x8(params, data, input, filter, bias,
                                         output);
      break;
    default:
      context->ReportError(context, "Type %d not currently supported.",
                           input->type);
      return kTfLiteError;
  }
}

template <KernelType kernel_type>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  const TfLiteTensor* input;
  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));

  switch (input->type) {  // Already know in/out types are same.
    case kTfLiteFloat32:
      return EvalImpl<kernel_type, kTfLiteFloat32>(context, node);
    case kTfLiteUInt8:
      return EvalImpl<kernel_type, kTfLiteUInt8>(context, node);
    case kTfLiteInt8:
      return EvalImpl<kernel_type, kTfLiteInt8>(context, node);
    case kTfLiteInt16:
      return EvalImpl<kernel_type, kTfLiteInt16>(context, node);
    default:
      context->ReportError(context, "Type %d not currently supported.",
                           input->type);
      return kTfLiteError;
  }
}

}  // namespace dihyzv

TfLiteRegistration* Register_dihyzv_REF() {
  static TfLiteRegistration r = {
      dihyzv::Init, dihyzv::Free, dihyzv::Prepare,
      dihyzv::Eval<dihyzv::kReference>};
  return &r;
}

TfLiteRegistration* Register_dihyzv_GENERIC_OPT() {
  static TfLiteRegistration r = {
      dihyzv::Init, dihyzv::Free, dihyzv::Prepare,
      dihyzv::Eval<dihyzv::kGenericOptimized>};
  return &r;
}

TfLiteRegistration* Register_dihyzv_NEON_OPT() {
  static TfLiteRegistration r = {
      dihyzv::Init, dihyzv::Free, dihyzv::Prepare,
      dihyzv::Eval<dihyzv::kNeonOptimized>};
  return &r;
}

TfLiteRegistration* Register_dihyzv_NEON_OPT_UINT8() {
  static TfLiteRegistration r = {
      dihyzv::Init, dihyzv::Free, dihyzv::Prepare,
      dihyzv::EvalImpl<dihyzv::kNeonOptimized, kTfLiteUInt8>};
  return &r;
}

TfLiteRegistration* Register_dihyzv() {
#ifdef USE_NEON
  return Register_dihyzv_NEON_OPT();
#else
  return Register_dihyzv_GENERIC_OPT();
#endif
}

// Warning: Clients using this variant are responsible for ensuring that their
// models only need the UINT8 type. TFLite's op registration mechanism doesn't
// yet allow for more nuanced registration mechanisms.
TfLiteRegistration* Register_dihyzv_UINT8() {
#ifdef USE_NEON
  return Register_dihyzv_NEON_OPT_UINT8();
#else
  return Register_dihyzv();
#endif
}

}  // namespace builtin
}  // namespace ops
}  // namespace tflite
